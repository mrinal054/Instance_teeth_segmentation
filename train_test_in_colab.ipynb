{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qq2-YoFxJyuC"
      },
      "source": [
        "**Current note:**\n",
        "* No augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XP_9wXtNCV7m",
        "outputId": "ccf9528b-6ec7-4816-b3a1-4ff1caff62d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uP7BfUAoCzUh"
      },
      "outputs": [],
      "source": [
        "# Set the system path for saving and loading libraries\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/library')\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/DNS_PanoramicDentalSeg/DNS_SMP')\n",
        "sys.path.append('/content/drive/MyDrive/teeth_instance/utils') # to import runtime_patch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dS5Hri-KFhtN"
      },
      "outputs": [],
      "source": [
        "# !pip install --target='/content/drive/MyDrive/library' timm==0.9.2\n",
        "# !pip install --target='/content/drive/MyDrive/library' pretrainedmodels==0.7.4\n",
        "# !pip install --target='/content/drive/MyDrive/library' efficientnet-pytorch==0.7.1\n",
        "# !pip install --target='/content/drive/MyDrive/library' git+https://github.com/qubvel/segmentation_models.pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8WWZRSrDagK"
      },
      "outputs": [],
      "source": [
        "import segmentation_models_pytorch as smp\n",
        "from segmentation_models_pytorch.utils import metrics, losses, base\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset as BaseDataset\n",
        "import albumentations as A\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from datetime import datetime\n",
        "from copy import deepcopy\n",
        "import pickle\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZoCkIucOqqu"
      },
      "source": [
        "### Data  generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5btwG5DxtFF6"
      },
      "outputs": [],
      "source": [
        "class Dataset(BaseDataset):\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            list_IDs,\n",
        "            images_dir,\n",
        "            masks_dir,\n",
        "            load_from_dir:bool = True,\n",
        "            prepatch:bool=None, # if true, patching is performed before augmentation, if false, patching after augmentation, if None, no patching\n",
        "            patch_shape:tuple = (256,256),\n",
        "            overlap:tuple = (0,0),\n",
        "            fg_prob:float = 0.9,\n",
        "            max_roi:bool = True,\n",
        "            augmentation=None,\n",
        "            preprocessing=None,\n",
        "            to_categorical:bool=False,\n",
        "            n_classes:int=33,\n",
        "    ):\n",
        "        self.ids = list_IDs\n",
        "        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids]\n",
        "        self.masks_fps = [os.path.join(masks_dir, image_id) for image_id in self.ids]\n",
        "        self.prepatch = prepatch\n",
        "        self.patch_shape = patch_shape\n",
        "        self.overlap = overlap\n",
        "        self.fg_prob = fg_prob\n",
        "        self.max_roi = max_roi\n",
        "        self.augmentation = augmentation\n",
        "        self.preprocessing = preprocessing\n",
        "        self.to_categorical = to_categorical\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "\n",
        "        # Add default image and mask. Colab sometimes does not find image/mask in a directory\n",
        "        # where there are many images. To avoid training termination, set default image and mask.\n",
        "        # So, if colab does not find an image, it will load default image.\n",
        "        self.default_image = os.path.join(images_dir, self.ids[0])\n",
        "        self.default_mask = os.path.join(masks_dir, self.ids[0])\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "\n",
        "        try:\n",
        "          # read data\n",
        "          image = cv2.imread(self.images_fps[i])[:,:,::-1]\n",
        "\n",
        "          mask = cv2.imread(self.masks_fps[i], 0) # graychannel\n",
        "          mask = np.expand_dims(mask, axis=-1)  # adding channel axis\n",
        "\n",
        "        except: # if colab can't catch the image and mask, then load the default image and mask to avoid runtime error\n",
        "          print(f'*************Exception occurred at: {self.images_fps[i]}', '\\n')\n",
        "          image = DEFAULT_IMAGE\n",
        "          mask = DEFAULT_MASK\n",
        "          mask = np.expand_dims(mask, axis=-1)\n",
        "\n",
        "        if self.prepatch is not None and self.prepatch: # apply patching before augmentation\n",
        "          image, mask = runtime_patch(image, mask, patch_shape=self.patch_shape , overlap=self.overlap, FG_PROB=0.9, MAX_ROI=self.max_roi)\n",
        "\n",
        "        # apply augmentations\n",
        "        if self.augmentation:\n",
        "            sample = self.augmentation(image=image, mask=mask)\n",
        "            image, mask = sample['image'], sample['mask']\n",
        "\n",
        "        if self.prepatch is not None and not self.prepatch: # apply patching after augmentation\n",
        "          image, mask = runtime_patch(image, mask, patch_shape=(256,256), overlap=(0,0), FG_PROB=self.fg_prob, MAX_ROI=True)\n",
        "\n",
        "        # apply preprocessing\n",
        "        if self.preprocessing:\n",
        "            sample = self.preprocessing(image=image, mask=mask)\n",
        "            image, mask = sample['image'], sample['mask']\n",
        "\n",
        "        if self.to_categorical:\n",
        "            mask = torch.from_numpy(mask)\n",
        "            mask = F.one_hot(mask.long(), num_classes=self.n_classes)\n",
        "            mask = mask.type(torch.float32)\n",
        "            mask = mask.numpy()\n",
        "            mask = np.squeeze(mask)\n",
        "\n",
        "            mask = np.moveaxis(mask, -1, 0) # e.g. 6 x 512 x 512. Only for smp\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ry5F0vHRQ0v-"
      },
      "source": [
        "### Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqgWL2ugQ3He"
      },
      "outputs": [],
      "source": [
        "def get_training_augmentation():\n",
        "    train_transform = [\n",
        "\n",
        "        A.OneOf(\n",
        "            [\n",
        "                A.HorizontalFlip(p=0.8),\n",
        "                A.VerticalFlip(p=0.4),\n",
        "            ],\n",
        "            p=0.5,\n",
        "        ),\n",
        "\n",
        "        A.OneOf(\n",
        "            [\n",
        "                A.ShiftScaleRotate(scale_limit=0.5, rotate_limit=0, shift_limit=0, p=1, border_mode=0), # scale only\n",
        "                A.ShiftScaleRotate(scale_limit=0, rotate_limit=30, shift_limit=0, p=1, border_mode=0), # rotate only\n",
        "                A.ShiftScaleRotate(scale_limit=0, rotate_limit=0, shift_limit=0.1, p=1, border_mode=0), # shift only\n",
        "                A.ShiftScaleRotate(scale_limit=0.5, rotate_limit=30, shift_limit=0.1, p=1, border_mode=0), # affine transform\n",
        "            ],\n",
        "            p=0.9,\n",
        "        ),\n",
        "\n",
        "\n",
        "        A.OneOf(\n",
        "            [\n",
        "                A.Perspective(p=1),\n",
        "                A.GaussNoise(p=1),\n",
        "                A.Sharpen(p=1),\n",
        "                A.Blur(blur_limit=3, p=1),\n",
        "                A.MotionBlur(blur_limit=3, p=1),\n",
        "            ],\n",
        "            p=0.2,\n",
        "        ),\n",
        "\n",
        "        A.OneOf(\n",
        "            [\n",
        "                A.CLAHE(p=1),\n",
        "                A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=1),\n",
        "                A.RandomGamma(p=1),\n",
        "                A.HueSaturationValue(p=1),\n",
        "            ],\n",
        "            p=0.2,\n",
        "        ),\n",
        "\n",
        "    ]\n",
        "\n",
        "    return A.Compose(train_transform, p=0.9, is_check_shapes=False) # 90% augmentation probability\n",
        "\n",
        "\n",
        "def get_validation_augmentation():\n",
        "    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n",
        "    test_transform = [\n",
        "        # A.PadIfNeeded(512, 512)\n",
        "    ]\n",
        "    return A.Compose(test_transform)\n",
        "\n",
        "\n",
        "def to_tensor(x, **kwargs):\n",
        "    return x.transpose(2, 0, 1).astype('float32')\n",
        "\n",
        "\n",
        "def get_preprocessing(preprocessing_fn):\n",
        "    \"\"\"Construct preprocessing transform\n",
        "\n",
        "    Args:\n",
        "        preprocessing_fn (callbale): data normalization function\n",
        "            (can be specific for each pretrained neural network)\n",
        "    Return:\n",
        "        transform: albumentations.Compose\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    _transform = [\n",
        "        A.Lambda(image=preprocessing_fn),\n",
        "        A.Lambda(image=to_tensor, mask=to_tensor),\n",
        "    ]\n",
        "    return A.Compose(_transform)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmhiHt2eRPbd"
      },
      "source": [
        "### Data directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39lZoWo1DdL0"
      },
      "outputs": [],
      "source": [
        "# Load directories for default image\n",
        "x_train_dir = '/content/drive/MyDrive/panoramicDNS/patchDNS_512/train/images' # patch images 512x512x3\n",
        "x_valid_dir = '/content/drive/MyDrive/panoramicDNS/patchDNS_512/val/images'\n",
        "y_train_dir = '/content/drive/MyDrive/panoramicDNS/patchDNS_512/train/mask'\n",
        "y_valid_dir = '/content/drive/MyDrive/panoramicDNS/patchDNS_512/val/mask'\n",
        "\n",
        "DEFAULT_IMAGE = cv2.imread(os.path.join(x_train_dir, os.listdir(x_train_dir)[0]))[:,:,::-1]\n",
        "DEFAULT_MASK = cv2.imread(os.path.join(y_train_dir, os.listdir(y_train_dir)[0]), 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxnOejL8RUqV",
        "outputId": "3b1c8e2e-c1e7-4d38-fd25-0f379c884912"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No. of training images:  4356\n",
            "No. of validation images:  828\n"
          ]
        }
      ],
      "source": [
        "list_IDs_train = os.listdir(x_train_dir)\n",
        "list_IDs_val = os.listdir(x_valid_dir)\n",
        "\n",
        "random.seed(42) # seed for random number generator\n",
        "\n",
        "random.shuffle(list_IDs_train) # shuffle names\n",
        "random.shuffle(list_IDs_val) # shuffle names\n",
        "\n",
        "print('No. of training images: ', len(list_IDs_train))\n",
        "print('No. of validation images: ', len(list_IDs_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhiug5frVIaa"
      },
      "source": [
        "### Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwipL9bpVCaz"
      },
      "outputs": [],
      "source": [
        "BASE_MODEL = 'FUSegNet'\n",
        "ENCODER = 'efficientnet-b7'\n",
        "ENCODER_WEIGHTS = 'imagenet'\n",
        "BATCH_SIZE = 2\n",
        "n_classes = 33\n",
        "ACTIVATION = 'softmax' # could be None for logits or 'softmax2d' for multiclass segmentation\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "LR = 0.0001 # learning rate\n",
        "EPOCHS = 50\n",
        "WEIGHT_DECAY = 1e-8 #1e-5\n",
        "SAVE_WEIGHTS_ONLY = True\n",
        "TO_CATEGORICAL = True\n",
        "SAVE_BEST_MODEL = True\n",
        "SAVE_LAST_MODEL = False\n",
        "PERIOD = 20 # periodically save checkpoints\n",
        "RAW_PREDICTION = False # if true, then stores raw predictions (i.e. before applying threshold)\n",
        "\n",
        "PATIENCE = 30 # for early stopping\n",
        "EARLY_STOP = True\n",
        "\n",
        "# Patch info\n",
        "PREPATCH = None # no patching\n",
        "PATCH_SHAPE = (512,512)\n",
        "OVERLAP = (0,0)\n",
        "FG_PROB = 0.5 # probability of selecting a foreground patch\n",
        "MAX_ROI = False # If true, then get the foreground patch which has max roi in the patch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55yzlovdXZHw"
      },
      "source": [
        "### Build model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhtKYtPcVaCy"
      },
      "outputs": [],
      "source": [
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-truTiUXUMg"
      },
      "outputs": [],
      "source": [
        "model_name = BASE_MODEL + '_' + ENCODER + '_' + datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
        "print(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwyuVMgcXb9g"
      },
      "source": [
        "**Checkpoint directory**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xdcpJXUWAeh"
      },
      "outputs": [],
      "source": [
        "# Checkpoint directory\n",
        "checkpoint_loc = '/content/drive/MyDrive/Colab Notebooks/DNS_PanoramicDentalSeg/DNS_SMP/checkpoints/' + model_name\n",
        "\n",
        "# Create checkpoint directory if does not exist\n",
        "if not os.path.exists(checkpoint_loc): os.makedirs(checkpoint_loc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsyTjWX3Xps6"
      },
      "source": [
        "**Helper function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0LDaawFXDU3"
      },
      "outputs": [],
      "source": [
        "# Helper function: save a model\n",
        "def save(model_path, epoch, model_state_dict, optimizer_state_dict):\n",
        "\n",
        "    state = {\n",
        "        'epoch': epoch + 1,\n",
        "        'state_dict': deepcopy(model_state_dict),\n",
        "        'optimizer': deepcopy(optimizer_state_dict),\n",
        "        }\n",
        "\n",
        "    torch.save(state, model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U221-v9gX1mC"
      },
      "source": [
        "**Loss function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVXNc_pBXyuY"
      },
      "outputs": [],
      "source": [
        "dice_loss = losses.DiceLoss()\n",
        "focal_loss = losses.FocalLoss()\n",
        "\n",
        "total_loss = base.SumOfLosses(dice_loss, focal_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dykOuZiX-fY"
      },
      "source": [
        "**Metrics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVEOK8enYADJ"
      },
      "outputs": [],
      "source": [
        "metrics = [\n",
        "    metrics.IoU(threshold=0.5),\n",
        "    metrics.Fscore(threshold=0.5),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4xzPCCpYIRp"
      },
      "source": [
        "**Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQ230xb2YAtA"
      },
      "outputs": [],
      "source": [
        "# Uncomment for FUSegNet + Gaten-attn\n",
        "model = smp.Unet(\n",
        "    encoder_name=ENCODER,\n",
        "    encoder_weights=ENCODER_WEIGHTS,\n",
        "    classes=n_classes,\n",
        "    activation=ACTIVATION,\n",
        "    decoder_attention_type = 'pscse',\n",
        ")\n",
        "\n",
        "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n",
        "\n",
        "model.to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from collections import OrderedDict\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def summary(model, input_size, batch_size=-1, device=\"cuda\"):\n",
        "\n",
        "    def register_hook(module):\n",
        "\n",
        "        def hook(module, input, output):\n",
        "            class_name = str(module.__class__).split(\".\")[-1].split(\"'\")[0]\n",
        "            module_idx = len(summary)\n",
        "\n",
        "            m_key = \"%s-%i\" % (class_name, module_idx + 1)\n",
        "            summary[m_key] = OrderedDict()\n",
        "\n",
        "            # following part is moderated by https://github.com/graykode/modelsummary/issues/1\n",
        "            if len(input) != 0:\n",
        "                summary[m_key][\"input_shape\"] = list(input[0].size())\n",
        "                summary[m_key][\"input_shape\"][0] = batch_size\n",
        "            else: summary[m_key][\"input_shape\"] = input\n",
        "\n",
        "\n",
        "            if isinstance(output, (list, tuple)):\n",
        "                summary[m_key][\"output_shape\"] = [\n",
        "                    [-1] + list(o.size())[1:] for o in output\n",
        "                ]\n",
        "            else:\n",
        "                summary[m_key][\"output_shape\"] = list(output.size())\n",
        "                summary[m_key][\"output_shape\"][0] = batch_size\n",
        "\n",
        "            params = 0\n",
        "            if hasattr(module, \"weight\") and hasattr(module.weight, \"size\"):\n",
        "                params += torch.prod(torch.LongTensor(list(module.weight.size())))\n",
        "                summary[m_key][\"trainable\"] = module.weight.requires_grad\n",
        "            if hasattr(module, \"bias\") and hasattr(module.bias, \"size\"):\n",
        "                params += torch.prod(torch.LongTensor(list(module.bias.size())))\n",
        "            summary[m_key][\"nb_params\"] = params\n",
        "\n",
        "        if (\n",
        "            not isinstance(module, nn.Sequential)\n",
        "            and not isinstance(module, nn.ModuleList)\n",
        "            and not (module == model)\n",
        "        ):\n",
        "            hooks.append(module.register_forward_hook(hook))\n",
        "\n",
        "    device = device.lower()\n",
        "    assert device in [\n",
        "        \"cuda\",\n",
        "        \"cpu\",\n",
        "    ], \"Input device is not valid, please specify 'cuda' or 'cpu'\"\n",
        "\n",
        "    if device == \"cuda\" and torch.cuda.is_available():\n",
        "        dtype = torch.cuda.FloatTensor\n",
        "    else:\n",
        "        dtype = torch.FloatTensor\n",
        "\n",
        "    # multiple inputs to the network\n",
        "    if isinstance(input_size, tuple):\n",
        "        input_size = [input_size]\n",
        "\n",
        "    # batch_size of 2 for batchnorm\n",
        "    x = [torch.rand(2, *in_size).type(dtype) for in_size in input_size]\n",
        "    # print(type(x[0]))\n",
        "\n",
        "    # create properties\n",
        "    summary = OrderedDict()\n",
        "    hooks = []\n",
        "\n",
        "    # register hook\n",
        "    model.apply(register_hook)\n",
        "\n",
        "    # make a forward pass\n",
        "    # print(x.shape)\n",
        "    model(*x)\n",
        "\n",
        "    # remove these hooks\n",
        "    for h in hooks:\n",
        "        h.remove()\n",
        "\n",
        "    print(\"----------------------------------------------------------------\")\n",
        "    line_new = \"{:>20}  {:>25} {:>15}\".format(\"Layer (type)\", \"Output Shape\", \"Param #\")\n",
        "    print(line_new)\n",
        "    print(\"================================================================\")\n",
        "    total_params = 0\n",
        "    total_output = 0\n",
        "    trainable_params = 0\n",
        "    for layer in summary:\n",
        "        # input_shape, output_shape, trainable, nb_params\n",
        "        line_new = \"{:>20}  {:>25} {:>15}\".format(\n",
        "            layer,\n",
        "            str(summary[layer][\"output_shape\"]),\n",
        "            \"{0:,}\".format(summary[layer][\"nb_params\"]),\n",
        "        )\n",
        "        total_params += summary[layer][\"nb_params\"]\n",
        "        total_output += np.prod(summary[layer][\"output_shape\"])\n",
        "        if \"trainable\" in summary[layer]:\n",
        "            if summary[layer][\"trainable\"] == True:\n",
        "                trainable_params += summary[layer][\"nb_params\"]\n",
        "        print(line_new)\n",
        "\n",
        "    # assume 4 bytes/number (float on cuda).\n",
        "    total_input_size = abs(np.prod(input_size) * batch_size * 4. / (1024 ** 2.))\n",
        "    total_output_size = abs(2. * total_output * 4. / (1024 ** 2.))  # x2 for gradients\n",
        "    total_params_size = abs(total_params.numpy() * 4. / (1024 ** 2.))\n",
        "    total_size = total_params_size + total_output_size + total_input_size\n",
        "\n",
        "    print(\"================================================================\")\n",
        "    print(\"Total params: {0:,}\".format(total_params))\n",
        "    print(\"Trainable params: {0:,}\".format(trainable_params))\n",
        "    print(\"Non-trainable params: {0:,}\".format(total_params - trainable_params))\n",
        "    print(\"----------------------------------------------------------------\")\n",
        "    print(\"Input size (MB): %0.2f\" % total_input_size)\n",
        "    print(\"Forward/backward pass size (MB): %0.2f\" % total_output_size)\n",
        "    print(\"Params size (MB): %0.2f\" % total_params_size)\n",
        "    print(\"Estimated Total Size (MB): %0.2f\" % total_size)\n",
        "    print(\"----------------------------------------------------------------\")\n",
        "    # return summary\n"
      ],
      "metadata": {
        "id": "RWFexPLbE8yq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model, (3, 512, 512))"
      ],
      "metadata": {
        "id": "DCgJvITvDiQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF-8g_xrYV-q"
      },
      "source": [
        "**Optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbQdzKJSYXeX"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam([\n",
        "    dict(params=model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbOk0zU4Ya4j"
      },
      "source": [
        "**Learning rate**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpTd4yL9YcZd"
      },
      "outputs": [],
      "source": [
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
        "                              factor=0.1,\n",
        "                              mode='min',\n",
        "                              patience=10,\n",
        "                              min_lr=0.00001,\n",
        "                              verbose=True,\n",
        "                              )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NE4RQ9XvZ80W"
      },
      "source": [
        "**Uncomment if you want to load a pretrained model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfP_eVIYZ8c3"
      },
      "outputs": [],
      "source": [
        "# pretrained_model_name = 'FUSegNet_gated_attn_efficientnet-b7_2023-07-08_14-39-11'\n",
        "# pretrained_cp_loc = '/content/drive/MyDrive/Colab Notebooks/DNS_PanoramicDentalSeg/DNS_SMP/checkpoints/' + pretrained_model_name\n",
        "\n",
        "# checkpoint = torch.load(os.path.join(pretrained_cp_loc, 'best_model.pth'))\n",
        "# model.load_state_dict(checkpoint['state_dict'])\n",
        "# optimizer.load_state_dict(checkpoint['optimizer'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KICuMQ73Yurv"
      },
      "source": [
        "**Dataloader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDlb0c49YmaU"
      },
      "outputs": [],
      "source": [
        "# Uncomment if you want to work with selected numbers of images\n",
        "selected_img = False\n",
        "if selected_img:\n",
        "  import random\n",
        "  random.shuffle(list_IDs_train)\n",
        "  random.shuffle(list_IDs_val)\n",
        "  list_IDs_train = list_IDs_train[:1000]\n",
        "  list_IDs_val = list_IDs_val[:100]\n",
        "  print(list_IDs_train)\n",
        "\n",
        "\n",
        "train_dataset = Dataset(\n",
        "    list_IDs_train,\n",
        "    x_train_dir,\n",
        "    y_train_dir,\n",
        "    prepatch=PREPATCH,\n",
        "    patch_shape=PATCH_SHAPE,\n",
        "    overlap=OVERLAP,\n",
        "    fg_prob=FG_PROB,\n",
        "    max_roi=MAX_ROI,\n",
        "    augmentation=get_validation_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocessing_fn),\n",
        "    to_categorical=TO_CATEGORICAL,\n",
        "    n_classes=n_classes,\n",
        ")\n",
        "\n",
        "valid_dataset = Dataset(\n",
        "    list_IDs_val,\n",
        "    x_valid_dir,\n",
        "    y_valid_dir,\n",
        "    prepatch=PREPATCH,\n",
        "    patch_shape=PATCH_SHAPE,\n",
        "    overlap=OVERLAP,\n",
        "    fg_prob=FG_PROB,\n",
        "    max_roi=MAX_ROI,\n",
        "    augmentation=get_validation_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocessing_fn),\n",
        "    to_categorical=TO_CATEGORICAL,\n",
        "    n_classes=n_classes,\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGGAz8oaZKKP"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YVusPR7bZLXx"
      },
      "outputs": [],
      "source": [
        "# create epoch runners\n",
        "# it is a simple loop of iterating over dataloader`s samples\n",
        "train_epoch = smp.utils.train.TrainEpoch(\n",
        "    model,\n",
        "    loss=total_loss,\n",
        "    metrics=metrics,\n",
        "    optimizer=optimizer,\n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "valid_epoch = smp.utils.train.ValidEpoch(\n",
        "    model,\n",
        "    loss=total_loss,\n",
        "    metrics=metrics,\n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "# train model for N epochs\n",
        "best_viou = 0.0\n",
        "best_vloss = 1_000_000.\n",
        "save_model = False\n",
        "cnt_patience = 0\n",
        "\n",
        "store_train_loss, store_val_loss = [], []\n",
        "store_train_iou, store_val_iou = [], []\n",
        "store_train_dice, store_val_dice = [], []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    print('\\nEpoch: {}'.format(epoch))\n",
        "    train_logs = train_epoch.run(train_loader)\n",
        "    valid_logs = valid_epoch.run(valid_loader)\n",
        "\n",
        "    # Store losses and metrics\n",
        "    train_loss_key = list(train_logs.keys())[0] # first key is for loss\n",
        "    val_loss_key = list(valid_logs.keys())[0] # first key is for loss\n",
        "\n",
        "    store_train_loss.append(train_logs[train_loss_key])\n",
        "    store_val_loss.append(valid_logs[val_loss_key])\n",
        "    store_train_iou.append(train_logs[\"iou_score\"])\n",
        "    store_val_iou.append(valid_logs[\"iou_score\"])\n",
        "    store_train_dice.append(train_logs[\"fscore\"])\n",
        "    store_val_dice.append(valid_logs[\"fscore\"])\n",
        "\n",
        "    # Track best performance, and save the model's state\n",
        "    if  best_vloss > valid_logs[val_loss_key]:\n",
        "        best_vloss = valid_logs[val_loss_key]\n",
        "        print(f'Validation loss reduced. Saving the model at epoch: {epoch:04d}')\n",
        "        cnt_patience = 0 # reset patience\n",
        "        best_model_epoch = epoch\n",
        "        save_model = True\n",
        "\n",
        "    # Compare iou score\n",
        "    elif best_viou < valid_logs['iou_score']:\n",
        "        best_viou = valid_logs['iou_score']\n",
        "        print(f'Validation IoU increased. Saving the model at epoch: {epoch:04d}.')\n",
        "        cnt_patience = 0 # reset patience\n",
        "        best_model_epoch = epoch\n",
        "        save_model = True\n",
        "\n",
        "    else: cnt_patience += 1\n",
        "\n",
        "    # Learning rate scheduler\n",
        "    scheduler.step(valid_logs[sorted(valid_logs.keys())[0]]) # monitor validation loss\n",
        "\n",
        "    # Save the model\n",
        "    if save_model:\n",
        "        save(os.path.join(checkpoint_loc, 'best_model' + '.pth'),\n",
        "             epoch+1, model.state_dict(), optimizer.state_dict())\n",
        "        save_model = False\n",
        "\n",
        "    # Early stopping\n",
        "    if EARLY_STOP and cnt_patience >= PATIENCE:\n",
        "      print(f\"Early stopping at epoch: {epoch:04d}\")\n",
        "      break\n",
        "\n",
        "    # Periodic checkpoint save\n",
        "    if not SAVE_BEST_MODEL:\n",
        "      if (epoch+1) % PERIOD == 0:\n",
        "        save(os.path.join(checkpoint_loc, f\"cp-{epoch+1:04d}.pth\"),\n",
        "             epoch+1, model.state_dict(), optimizer.state_dict())\n",
        "        print(f'Checkpoint saved for epoch {epoch:04d}')\n",
        "\n",
        "if not EARLY_STOP and SAVE_LAST_MODEL:\n",
        "    print('Saving last model')\n",
        "    save(os.path.join(checkpoint_loc, 'last_model' + '.pth'),\n",
        "         epoch+1, model.state_dict(), optimizer.state_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JOcdqag5uH0N"
      },
      "outputs": [],
      "source": [
        "best_model_epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIjvp0g-Zrb-"
      },
      "source": [
        "**Plotting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Yjo9LSBHZpuP"
      },
      "outputs": [],
      "source": [
        "\"\"\"## Plotting \"\"\"\n",
        "fig, ax = plt.subplots(3,1, figsize=(7, 14))\n",
        "\n",
        "ax[0].plot(store_train_loss, 'r')\n",
        "ax[0].plot(store_val_loss, 'b')\n",
        "ax[0].set_title('Loss curve')\n",
        "ax[0].legend(['training', 'validation'])\n",
        "\n",
        "ax[1].plot(store_train_iou, 'r')\n",
        "ax[1].plot(store_val_iou, 'b')\n",
        "ax[1].set_title('IoU curve')\n",
        "ax[1].legend(['training', 'validation'])\n",
        "\n",
        "ax[2].plot(store_train_iou, 'r')\n",
        "ax[2].plot(store_val_iou, 'b')\n",
        "ax[2].set_title('Dice curve')\n",
        "ax[2].legend(['training', 'validation'])\n",
        "\n",
        "fig.tight_layout()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "save_fig_dir = '/content/drive/MyDrive/Colab Notebooks/DNS_PanoramicDentalSeg/DNS_SMP/plots/'\n",
        "if not os.path.exists(save_fig_dir): os.makedirs(save_fig_dir)\n",
        "\n",
        "fig.savefig(os.path.join(save_fig_dir, model_name + '.png'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZW5A9qLNW7ug"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6FB31XdSW6ML"
      },
      "outputs": [],
      "source": [
        "from jenti.patch import Patch, Merge\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import scipy.io as sio\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmBM4ej1Yiag"
      },
      "source": [
        "**Test image directory**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_CzRZUTnX0nK",
        "outputId": "44e8a897-8870-4533-86b1-9e7153446738"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No. of test images:  111\n"
          ]
        }
      ],
      "source": [
        "# Directories\n",
        "x_test_dir = '/content/drive/MyDrive/panoramicDNS/fold5/images'\n",
        "y_test_dir = '/content/drive/MyDrive/panoramicDNS/fold5/masks'\n",
        "\n",
        "list_IDs_test = os.listdir(x_test_dir)\n",
        "print('No. of test images: ', len(list_IDs_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqcFncpHZdsC"
      },
      "source": [
        "**Test dataloader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MHONK8TQZfyA"
      },
      "outputs": [],
      "source": [
        "# Image preprocessing function\n",
        "im_preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vdf-C6MhZbII"
      },
      "source": [
        "**Load model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tAEzJnzbZYkF"
      },
      "outputs": [],
      "source": [
        "checkpoint = torch.load(os.path.join(checkpoint_loc, 'best_model.pth'))\n",
        "model.load_state_dict(checkpoint['state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "\n",
        "# Uncomment if to load periodically saved checkpoints\n",
        "# model = torch.load(os.path.join(checkpoint_loc, 'cp-0050.pth'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcEz2h_cYl5g"
      },
      "source": [
        "**Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9c9j9j6RYDHE"
      },
      "outputs": [],
      "source": [
        "save_pred = True\n",
        "threshold = 0.5\n",
        "ep = 1e-6\n",
        "raw_pred = []\n",
        "patch_shape = [512, 512]\n",
        "overlap = [0, 0]\n",
        "\n",
        "HARD_LINE = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qm55VujpYrbb"
      },
      "source": [
        "**Set directory to store predictions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "P33mlwyiYpWg"
      },
      "outputs": [],
      "source": [
        "# Save directory\n",
        "save_dir_pred = '/content/drive/MyDrive/Colab Notebooks/DNS_PanoramicDentalSeg/DNS_SMP/predictions/' + model_name\n",
        "if not os.path.exists(save_dir_pred): os.makedirs(save_dir_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZbIQiYUUZJLA"
      },
      "outputs": [],
      "source": [
        "# Create dataframe to store records\n",
        "df = pd.DataFrame(index=[], columns = [\n",
        "    'Name', 'Accuracy', 'Specificity', 'iou', 'Precision', 'Recall', 'Dice'], dtype='object')\n",
        "\n",
        "# Create a dictionary to store metrics\n",
        "metric = {} # Nested metric format: metric[image_name][label] = [precision, recall, dice, iou]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kgzUOzUEZkyb"
      },
      "outputs": [],
      "source": [
        "stp, stn, sfp, sfn = 0, 0, 0, 0\n",
        "for i, name_ext in enumerate(list_IDs_test):\n",
        "\n",
        "    tp, tn, fp, fn = 0, 0, 0, 0\n",
        "\n",
        "    name = os.path.splitext(name_ext)[0] # remove extension\n",
        "\n",
        "    metric[name] = {} # Creating nested dictionary\n",
        "\n",
        "    # Image-wise mean of metrics\n",
        "    i_mp, i_mr, i_mdice, i_miou = [], [], [], []\n",
        "\n",
        "    # Load image and mask\n",
        "    image = cv2.imread(os.path.join(x_test_dir, name + '.jpg'))[:,:,::-1]\n",
        "    gt_mask = cv2.imread(os.path.join(y_test_dir, name + '.png'), 0) # gt is grayscale\n",
        "\n",
        "    # Preprocess image\n",
        "    image = im_preprocessing_fn(image)\n",
        "\n",
        "    # Create patches from the image\n",
        "    patch = Patch(patch_shape, overlap, patch_name=name, csv_output=False)\n",
        "    patches, info, org_shape_im = patch.patch2d(image)\n",
        "    org_shape_mask = (org_shape_im[0], org_shape_im[1], 1) # mask is a grayscale image\n",
        "\n",
        "    # Iterate over patches\n",
        "    patchwise_pred = [] # store patch-wise predictions for each test sample\n",
        "    for patch in patches:\n",
        "      patch = np.expand_dims(patch, axis=0) # shape: 1 x 512 x 512 x 3\n",
        "      patch = np.moveaxis(patch, -1, 1).astype('float32') # shape: 1 x 3 x 512 x 512\n",
        "      patch = torch.from_numpy(patch) # convert to tensor\n",
        "      pr_mask = model.predict(patch.to(DEVICE)) # Move image tensor to gpu\n",
        "\n",
        "      if TO_CATEGORICAL:\n",
        "        pr_mask = torch.argmax(pr_mask, dim=1) # shape: 1 x 512 x 512\n",
        "      pr_mask = pr_mask.squeeze().cpu().numpy() # move to cpu; shape: 512 x 512\n",
        "      pr_mask = np.expand_dims(pr_mask, axis=-1) # shape: 512 x 512 x 1\n",
        "      patchwise_pred.append(pr_mask)\n",
        "\n",
        "    # Merge patches\n",
        "    merge = Merge(info, org_shape_mask, dtype='int8') # create object\n",
        "    merged = merge.merge2d(patchwise_pred)\n",
        "\n",
        "    # Move to CPU and convert to numpy\n",
        "    gt_mask = np.squeeze(gt_mask)\n",
        "    pred = np.squeeze(merged)\n",
        "\n",
        "    # Save raw prediction\n",
        "    if RAW_PREDICTION: raw_pred.append(pred)\n",
        "\n",
        "    # Save prediction as png\n",
        "    if save_pred:\n",
        "        cv2.imwrite(os.path.join(save_dir_pred, name + '.png'), np.squeeze(pred).astype(np.uint8))\n",
        "\n",
        "    # Find labels in gt and prediction\n",
        "    lbl_gt = set(np.unique(gt_mask))\n",
        "    lbl_gt.remove(0) # remove 0. It is background\n",
        "    lbl_pred = set(np.unique(pred))\n",
        "    lbl_pred.remove(0) # remove 0. It is background\n",
        "\n",
        "    # All labels\n",
        "    all_lbls = lbl_gt.union(lbl_pred)\n",
        "\n",
        "    # Find labels that are not common in both gt and prediction. For such cases. IoU = 0\n",
        "    diff1 = lbl_gt - lbl_pred\n",
        "    diff2 = lbl_pred - lbl_gt\n",
        "    diffs = diff1.union(diff2) # labels that do not exist in either gt or prediction\n",
        "\n",
        "    # Labels that are in the gt but not in prediction are fn\n",
        "    if len(diff1) > 0:\n",
        "        for d1 in diff1:\n",
        "            fn_ = len(np.argwhere(gt_mask == d1))\n",
        "            fn += fn_\n",
        "            sfn += fn\n",
        "\n",
        "    # Labels that are in the prediction but not in gt are fp\n",
        "    if len(diff2) > 0:\n",
        "        for d2 in diff2:\n",
        "            fp_ = len(np.argwhere(pred == d2))\n",
        "            fp += fp_\n",
        "            sfp += fp\n",
        "\n",
        "    # Set IoU == 0 for such labels\n",
        "    if not len(diffs) == 0:\n",
        "      for diff in diffs:\n",
        "        p, r, dice, iou = 0, 0, 0, 0\n",
        "        metric[name][str(diff)] = [p, r, dice, iou]\n",
        "        print(\"%d %s: label: %s; Precision: %3.2f; Recall: %3.2f; Dice: %3.2f; IoU: %3.2f\"%(i+1, name, diff, p, r, dice, iou))\n",
        "\n",
        "    # Find labels that are common in both gt and prediction.\n",
        "    cmns = lbl_gt.intersection(lbl_pred)\n",
        "\n",
        "    # Iterate over common labels\n",
        "    for cmn in cmns:\n",
        "        gt_idx = np.where(gt_mask == cmn)\n",
        "        pred_idx = np.where(pred == cmn)\n",
        "\n",
        "        # Convert to [(x1,y1), (x2,y2), ...]\n",
        "        gt_lidx, pred_lidx = [], [] # List index\n",
        "\n",
        "        for i in range(len(gt_idx[0])):\n",
        "            gt_lidx.append((gt_idx[0][i], gt_idx[1][i]))\n",
        "\n",
        "        for i in range(len(pred_idx[0])):\n",
        "            pred_lidx.append((pred_idx[0][i], pred_idx[1][i]))\n",
        "\n",
        "        # Calculate metrics\n",
        "        gt_tidx = tuple(gt_lidx) # convert to tuple\n",
        "        pred_tidx = tuple(pred_lidx) # convert to tuple\n",
        "        tp_cord = set(gt_tidx).intersection(pred_tidx) # set operation\n",
        "        fp_cord = set(pred_tidx).difference(gt_tidx) # set operation\n",
        "        fn_cord = set(gt_tidx).difference(pred_tidx) # set operation\n",
        "\n",
        "        tp += len(tp_cord)\n",
        "        fp += len(fp_cord)\n",
        "        fn += len(fn_cord)\n",
        "\n",
        "        stp += tp\n",
        "        sfp += fp\n",
        "        sfn += fn\n",
        "\n",
        "        p = (tp/(tp + fp + ep)) * 100\n",
        "        r = (tp/(tp + fn + ep)) * 100\n",
        "        dice = (2 * tp / (2 * tp + fp + fn + ep)) * 100\n",
        "        iou = (tp/(tp + fp + fn + ep)) * 100\n",
        "\n",
        "        print(\"%d %s: label: %s; Precision: %3.2f; Recall: %3.2f; Dice: %3.2f; IoU: %3.2f\"%(i+1, name, cmn, p, r, dice, iou))\n",
        "\n",
        "        metric[name][str(cmn)] = [p, r, dice, iou]\n",
        "\n",
        "        # Keep appending metrics for all labels for the current image\n",
        "        i_mp.append(p)\n",
        "        i_mr.append(r)\n",
        "        i_mdice.append(dice)\n",
        "        i_miou.append(iou)\n",
        "\n",
        "    # Calculate mean of metrics for the current image\n",
        "    i_mp = np.mean(i_mp)\n",
        "    i_mr = np.mean(i_mr)\n",
        "    i_mdice = np.mean(i_mdice)\n",
        "    i_miou = np.mean(i_miou)\n",
        "\n",
        "    # Store results in the data frame\n",
        "    tmp = pd.Series([name, i_mp, i_mr, i_mdice, i_miou], index=['Name', 'Precision', 'Recall', 'Dice', 'IoU'])\n",
        "    df = df.append(tmp, ignore_index = True)\n",
        "\n",
        "# Print overall mean of metrics\n",
        "print(\"Image-based all IoU: %3.2f\" % df[\"IoU\"].mean())\n",
        "print(\"Image-based precision: %3.2f\" % df[\"Precision\"].mean())\n",
        "print(\"Image-based all Recall: %3.2f\" % df[\"Recall\"].mean())\n",
        "print(\"Image-based all dice: %3.2f\" % df[\"Dice\"].mean())\n",
        "\n",
        "df.to_excel(os.path.join(save_dir_pred, 'result_image_based.xlsx'), index=False)\n",
        "\n",
        "# create json object from dictionary\n",
        "import json\n",
        "json_write = json.dumps(metric)\n",
        "f = open(os.path.join(save_dir_pred, \"metric.json\"), \"w\")\n",
        "f.write(json_write)\n",
        "f.close()\n",
        "\n",
        "# Data-based evalutation\n",
        "siou = (stp/(stp + sfp + sfn + ep))*100\n",
        "sprecision = (stp/(stp + sfp + ep))*100\n",
        "srecall = (stp/(stp + sfn + ep))*100\n",
        "sdice = (2 * stp / (2 * stp + sfp + sfn))*100\n",
        "\n",
        "print('siou:', siou)\n",
        "print('sprecision:', sprecision)\n",
        "print('srecall:', srecall)\n",
        "print('sdice:', sdice)\n",
        "\n",
        "# Save data-based result in a text file\n",
        "with open(os.path.join(save_dir_pred, 'result_data_based_best_model.txt'), 'w') as f:\n",
        "    print(f'siou = {siou}', file=f)\n",
        "    print(f'sprecision = {sprecision}', file=f)\n",
        "    print(f'srecall = {srecall}', file=f)\n",
        "    print(f'sdice = {sdice}', file=f)\n",
        "    print(f'best model epoch = {best_model_epoch}', file=f)\n",
        "    print(f'model name = {model_name}', file=f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fk68u9wbfLxs"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}